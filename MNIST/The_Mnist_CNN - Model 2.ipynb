{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist.load_data()\n",
    "mnist_train, mnist_test = mnist_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_inputs, train_targets = mnist_train[0] / 255., mnist_train[1]\n",
    "scaled_test_inputs, test_targets = mnist_test[0] / 255., mnist_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "shuffled_indices = np.arange(scaled_train_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_train_inputs, shuffled_train_targets = scaled_train_inputs[shuffled_indices], train_targets[shuffled_indices]\n",
    "\n",
    "#test data\n",
    "shuffled_indices = np.arange(scaled_test_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffled_test_inputs, shuffled_test_targets = scaled_test_inputs[shuffled_indices], test_targets[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "num_validation_samples = int(0.1 * shuffled_train_inputs.shape[0])\n",
    "\n",
    "train_inputs = shuffled_train_inputs[num_validation_samples:].reshape((-1, 28, 28, 1))\n",
    "train_targets = shuffled_train_targets[num_validation_samples:]\n",
    "\n",
    "validation_inputs = shuffled_train_inputs[:num_validation_samples].reshape((-1, 28, 28, 1))\n",
    "validation_targets = shuffled_train_targets[:num_validation_samples]\n",
    "\n",
    "test_inputs, test_targets = shuffled_test_inputs.reshape((-1, 28, 28, 1)), shuffled_test_targets\n",
    "\n",
    "print(train_inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a best practise to define some constants/hyperparameters in a visible place\n",
    "\n",
    "max_epochs = 20\n",
    "batch_size = 256 # A value that's a power of 2\n",
    "steps_per_epoch = 100\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters we would tune, and their values to be tested\n",
    "HP_FILTER_NUM = hp.HParam('filters_number', hp.Discrete([64, 96, 128]))\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([5, 7]))\n",
    "\n",
    "# Logging setup info\n",
    "with tf.summary.create_file_writer('logs\\\\Model 2\\\\hparam_tuning\\\\').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams = [HP_FILTER_NUM, HP_FILTER_SIZE],\n",
    "        metrics = [hp.Metric('accuracy', display_name='Accuracy')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping our model and training in a function\n",
    "def train_test_model(hparams, session_num):\n",
    "    \n",
    "    # Outlining the model/architecture of our CNN\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(hparams[HP_FILTER_NUM], hparams[HP_FILTER_SIZE], activation='relu', input_shape=(28, 28, 1)),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        keras.layers.Conv2D(hparams[HP_FILTER_NUM], 3, activation='relu'),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(output_size)\n",
    "    ])\n",
    "    \n",
    "    # Defining the loss function\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    # Compiling the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining the logging directory\n",
    "    log_dir = \"logs\\\\Model 2\\\\fit\\\\\" + \"run-{}\".format(session_num)\n",
    "\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names, normalized=True):\n",
    "\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "        Args:\n",
    "        cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "        class_names (array, shape = [n]): String names of the integer classes\n",
    "        \"\"\"\n",
    "\n",
    "        figure = plt.figure(figsize=(12, 12))\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Normalize the confusion matrix.\n",
    "        if not normalized:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        cm = np.around(cm.astype('float'), decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "\n",
    "        plt.tight_layout() # Adjust the padding\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        return figure\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "        \"\"\"Converts the matplotlib plot specified with 'figure' to a PNG image and returns it,\n",
    "        The supplied figure is closed and inaccessible after this call.\n",
    "        \"\"\"\n",
    "\n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "\n",
    "        # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "        plt.close()\n",
    "\n",
    "        # Convert the PNG buffer to TF image.\n",
    "        buf.seek(0)\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "\n",
    "        # Add the batch dimension.\n",
    "        image = tf.expand_dims(image, 0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "    # Define a file writer variable for the logging purposes\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "    # The lambda callback to be called should have the (epoch, logs) parameters\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "\n",
    "        predictions_raw = model.predict(validation_inputs)\n",
    "        predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "        cm = confusion_matrix(validation_targets, predictions, normalize='true')\n",
    "\n",
    "        # Log the confusion matrix as an image.\n",
    "        figure = plot_confusion_matrix(cm, ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], True)\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image('Confusion Matrix', cm_image, step=epoch)\n",
    "            \n",
    "    \n",
    "    # Define the Tensorboard and Confusion Matrix callbacks.\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)\n",
    "    cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        train_inputs,\n",
    "        train_targets,\n",
    "        batch_size=batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=[tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data=(validation_inputs, validation_targets),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Evaluating the model's performance on the validation set\n",
    "    _, accuracy = model.evaluate(validation_inputs, validation_targets)\n",
    "    \n",
    "    # Saving the current model for future reference\n",
    "    model.save(r\"saved_models\\Model 2\\Run-{}\".format(session_num))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams, session_num):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams, session_num)\n",
    "        tf.summary.scalar('accuracy', accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-1\n",
      "{'filter_size': 3, 'filters_number': 32}\n",
      "Epoch 1/20\n",
      "422/422 - 18s - loss: 0.3565 - accuracy: 0.9038 - val_loss: 0.1246 - val_accuracy: 0.9638\n",
      "Epoch 2/20\n",
      "422/422 - 17s - loss: 0.0921 - accuracy: 0.9722 - val_loss: 0.0917 - val_accuracy: 0.9723\n",
      "Epoch 3/20\n",
      "422/422 - 18s - loss: 0.0669 - accuracy: 0.9799 - val_loss: 0.0763 - val_accuracy: 0.9752\n",
      "Epoch 4/20\n",
      "422/422 - 18s - loss: 0.0541 - accuracy: 0.9835 - val_loss: 0.0702 - val_accuracy: 0.9785\n",
      "Epoch 5/20\n",
      "422/422 - 18s - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.0651 - val_accuracy: 0.9810\n",
      "Epoch 6/20\n",
      "422/422 - 18s - loss: 0.0408 - accuracy: 0.9874 - val_loss: 0.0556 - val_accuracy: 0.9848\n",
      "Epoch 7/20\n",
      "422/422 - 18s - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.0561 - val_accuracy: 0.9842\n",
      "Epoch 8/20\n",
      "422/422 - 18s - loss: 0.0327 - accuracy: 0.9901 - val_loss: 0.0572 - val_accuracy: 0.9848\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9848\n",
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\pc\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-1\\assets\n",
      "--- Starting trial: run-2\n",
      "{'filter_size': 3, 'filters_number': 64}\n",
      "Epoch 1/20\n",
      "422/422 - 35s - loss: 0.2677 - accuracy: 0.9234 - val_loss: 0.1147 - val_accuracy: 0.9653\n",
      "Epoch 2/20\n",
      "422/422 - 34s - loss: 0.0695 - accuracy: 0.9788 - val_loss: 0.0715 - val_accuracy: 0.9797\n",
      "Epoch 3/20\n",
      "422/422 - 35s - loss: 0.0514 - accuracy: 0.9844 - val_loss: 0.0609 - val_accuracy: 0.9822\n",
      "Epoch 4/20\n",
      "422/422 - 36s - loss: 0.0406 - accuracy: 0.9878 - val_loss: 0.0542 - val_accuracy: 0.9840\n",
      "Epoch 5/20\n",
      "422/422 - 36s - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.0505 - val_accuracy: 0.9848\n",
      "Epoch 6/20\n",
      "422/422 - 37s - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0460 - val_accuracy: 0.9882\n",
      "Epoch 7/20\n",
      "422/422 - 37s - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0552 - val_accuracy: 0.9853\n",
      "Epoch 8/20\n",
      "422/422 - 36s - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0481 - val_accuracy: 0.9863\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0460 - accuracy: 0.9882\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-2\\assets\n",
      "--- Starting trial: run-3\n",
      "{'filter_size': 3, 'filters_number': 96}\n",
      "Epoch 1/20\n",
      "422/422 - 55s - loss: 0.2286 - accuracy: 0.9326 - val_loss: 0.0859 - val_accuracy: 0.9738\n",
      "Epoch 2/20\n",
      "422/422 - 69s - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0838 - val_accuracy: 0.9743\n",
      "Epoch 3/20\n",
      "422/422 - 72s - loss: 0.0458 - accuracy: 0.9864 - val_loss: 0.0654 - val_accuracy: 0.9817\n",
      "Epoch 4/20\n",
      "422/422 - 71s - loss: 0.0360 - accuracy: 0.9893 - val_loss: 0.0529 - val_accuracy: 0.9828\n",
      "Epoch 5/20\n",
      "422/422 - 71s - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0586 - val_accuracy: 0.9855\n",
      "Epoch 6/20\n",
      "422/422 - 72s - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0461 - val_accuracy: 0.9870\n",
      "Epoch 7/20\n",
      "422/422 - 71s - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.0445 - val_accuracy: 0.9887\n",
      "Epoch 8/20\n",
      "422/422 - 71s - loss: 0.0165 - accuracy: 0.9946 - val_loss: 0.0478 - val_accuracy: 0.9873\n",
      "Epoch 9/20\n",
      "422/422 - 71s - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0438 - val_accuracy: 0.9888\n",
      "Epoch 10/20\n",
      "422/422 - 73s - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0510 - val_accuracy: 0.9887\n",
      "Epoch 11/20\n",
      "422/422 - 74s - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.0568 - val_accuracy: 0.9875\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0438 - accuracy: 0.9888\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-3\\assets\n",
      "--- Starting trial: run-4\n",
      "{'filter_size': 3, 'filters_number': 128}\n",
      "Epoch 1/20\n",
      "422/422 - 99s - loss: 0.2054 - accuracy: 0.9391 - val_loss: 0.0860 - val_accuracy: 0.9725\n",
      "Epoch 2/20\n",
      "422/422 - 102s - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.0582 - val_accuracy: 0.9833\n",
      "Epoch 3/20\n",
      "422/422 - 102s - loss: 0.0418 - accuracy: 0.9869 - val_loss: 0.0512 - val_accuracy: 0.9855\n",
      "Epoch 4/20\n",
      "422/422 - 102s - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.0471 - val_accuracy: 0.9857\n",
      "Epoch 5/20\n",
      "422/422 - 102s - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.0528 - val_accuracy: 0.9862\n",
      "Epoch 6/20\n",
      "422/422 - 102s - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0456 - val_accuracy: 0.9877\n",
      "Epoch 7/20\n",
      "422/422 - 102s - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0458 - val_accuracy: 0.9882\n",
      "Epoch 8/20\n",
      "422/422 - 102s - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0435 - val_accuracy: 0.9895\n",
      "Epoch 9/20\n",
      "422/422 - 101s - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 10/20\n",
      "422/422 - 103s - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0498 - val_accuracy: 0.9883\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0435 - accuracy: 0.9895\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-4\\assets\n",
      "--- Starting trial: run-5\n",
      "{'filter_size': 5, 'filters_number': 32}\n",
      "Epoch 1/20\n",
      "422/422 - 26s - loss: 0.3106 - accuracy: 0.9162 - val_loss: 0.1233 - val_accuracy: 0.9630\n",
      "Epoch 2/20\n",
      "422/422 - 26s - loss: 0.0854 - accuracy: 0.9744 - val_loss: 0.0803 - val_accuracy: 0.9788\n",
      "Epoch 3/20\n",
      "422/422 - 26s - loss: 0.0621 - accuracy: 0.9811 - val_loss: 0.0763 - val_accuracy: 0.9780\n",
      "Epoch 4/20\n",
      "422/422 - 26s - loss: 0.0518 - accuracy: 0.9839 - val_loss: 0.0637 - val_accuracy: 0.9813\n",
      "Epoch 5/20\n",
      "422/422 - 27s - loss: 0.0437 - accuracy: 0.9870 - val_loss: 0.0554 - val_accuracy: 0.9845\n",
      "Epoch 6/20\n",
      "422/422 - 26s - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0476 - val_accuracy: 0.9875\n",
      "Epoch 7/20\n",
      "422/422 - 27s - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0517 - val_accuracy: 0.9853\n",
      "Epoch 8/20\n",
      "422/422 - 25s - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.0528 - val_accuracy: 0.9863\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0476 - accuracy: 0.9875\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-5\\assets\n",
      "--- Starting trial: run-6\n",
      "{'filter_size': 5, 'filters_number': 64}\n",
      "Epoch 1/20\n",
      "422/422 - 45s - loss: 0.2516 - accuracy: 0.9285 - val_loss: 0.0904 - val_accuracy: 0.9715\n",
      "Epoch 2/20\n",
      "422/422 - 45s - loss: 0.0647 - accuracy: 0.9800 - val_loss: 0.0626 - val_accuracy: 0.9797\n",
      "Epoch 3/20\n",
      "422/422 - 46s - loss: 0.0486 - accuracy: 0.9851 - val_loss: 0.0582 - val_accuracy: 0.9845\n",
      "Epoch 4/20\n",
      "422/422 - 45s - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.0470 - val_accuracy: 0.9865\n",
      "Epoch 5/20\n",
      "422/422 - 35s - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0481 - val_accuracy: 0.9853\n",
      "Epoch 6/20\n",
      "422/422 - 33s - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0472 - val_accuracy: 0.9875\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0470 - accuracy: 0.9865\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-6\\assets\n",
      "--- Starting trial: run-7\n",
      "{'filter_size': 5, 'filters_number': 96}\n",
      "Epoch 1/20\n",
      "422/422 - 50s - loss: 0.2093 - accuracy: 0.9388 - val_loss: 0.0784 - val_accuracy: 0.9750\n",
      "Epoch 2/20\n",
      "422/422 - 49s - loss: 0.0566 - accuracy: 0.9827 - val_loss: 0.0526 - val_accuracy: 0.9845\n",
      "Epoch 3/20\n",
      "422/422 - 49s - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.0547 - val_accuracy: 0.9842\n",
      "Epoch 4/20\n",
      "422/422 - 48s - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.0517 - val_accuracy: 0.9853\n",
      "Epoch 5/20\n",
      "422/422 - 52s - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
      "Epoch 6/20\n",
      "422/422 - 52s - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0423 - val_accuracy: 0.9890\n",
      "Epoch 7/20\n",
      "422/422 - 50s - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0411 - val_accuracy: 0.9902\n",
      "Epoch 8/20\n",
      "422/422 - 52s - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0476 - val_accuracy: 0.9868\n",
      "Epoch 9/20\n",
      "422/422 - 51s - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0459 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 2s 9ms/step - loss: 0.0411 - accuracy: 0.9902\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-7\\assets\n",
      "--- Starting trial: run-8\n",
      "{'filter_size': 5, 'filters_number': 128}\n",
      "Epoch 1/20\n",
      "422/422 - 77s - loss: 0.1875 - accuracy: 0.9453 - val_loss: 0.0735 - val_accuracy: 0.9780\n",
      "Epoch 2/20\n",
      "422/422 - 74s - loss: 0.0535 - accuracy: 0.9827 - val_loss: 0.0623 - val_accuracy: 0.9818\n",
      "Epoch 3/20\n",
      "422/422 - 71s - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.0527 - val_accuracy: 0.9843\n",
      "Epoch 4/20\n",
      "422/422 - 73s - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 5/20\n",
      "422/422 - 70s - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.0409 - val_accuracy: 0.9893\n",
      "Epoch 6/20\n",
      "422/422 - 71s - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0400 - val_accuracy: 0.9897\n",
      "Epoch 7/20\n",
      "422/422 - 68s - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0414 - val_accuracy: 0.9907\n",
      "Epoch 8/20\n",
      "422/422 - 69s - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.0447 - val_accuracy: 0.9882\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.0400 - accuracy: 0.9897\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-8\\assets\n",
      "--- Starting trial: run-9\n",
      "{'filter_size': 7, 'filters_number': 32}\n",
      "Epoch 1/20\n",
      "422/422 - 17s - loss: 0.3416 - accuracy: 0.9039 - val_loss: 0.1386 - val_accuracy: 0.9582\n",
      "Epoch 2/20\n",
      "422/422 - 18s - loss: 0.0979 - accuracy: 0.9707 - val_loss: 0.0913 - val_accuracy: 0.9712\n",
      "Epoch 3/20\n",
      "422/422 - 17s - loss: 0.0703 - accuracy: 0.9788 - val_loss: 0.0727 - val_accuracy: 0.9787\n",
      "Epoch 4/20\n",
      "422/422 - 17s - loss: 0.0584 - accuracy: 0.9821 - val_loss: 0.0681 - val_accuracy: 0.9790\n",
      "Epoch 5/20\n",
      "422/422 - 17s - loss: 0.0491 - accuracy: 0.9846 - val_loss: 0.0643 - val_accuracy: 0.9795\n",
      "Epoch 6/20\n",
      "422/422 - 18s - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.0629 - val_accuracy: 0.9810\n",
      "Epoch 7/20\n",
      "422/422 - 17s - loss: 0.0382 - accuracy: 0.9879 - val_loss: 0.0553 - val_accuracy: 0.9833\n",
      "Epoch 8/20\n",
      "422/422 - 18s - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0505 - val_accuracy: 0.9857\n",
      "Epoch 9/20\n",
      "422/422 - 17s - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.0484 - val_accuracy: 0.9857\n",
      "Epoch 10/20\n",
      "422/422 - 18s - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0539 - val_accuracy: 0.9842\n",
      "Epoch 11/20\n",
      "422/422 - 17s - loss: 0.0252 - accuracy: 0.9922 - val_loss: 0.0461 - val_accuracy: 0.9872\n",
      "Epoch 12/20\n",
      "422/422 - 17s - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.0525 - val_accuracy: 0.9852\n",
      "Epoch 13/20\n",
      "422/422 - 18s - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0513 - val_accuracy: 0.9850\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0461 - accuracy: 0.9872\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-9\\assets\n",
      "--- Starting trial: run-10\n",
      "{'filter_size': 7, 'filters_number': 64}\n",
      "Epoch 1/20\n",
      "422/422 - 31s - loss: 0.2624 - accuracy: 0.9286 - val_loss: 0.1087 - val_accuracy: 0.9658\n",
      "Epoch 2/20\n",
      "422/422 - 32s - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.0725 - val_accuracy: 0.9760\n",
      "Epoch 3/20\n",
      "422/422 - 31s - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.0590 - val_accuracy: 0.9825\n",
      "Epoch 4/20\n",
      "422/422 - 32s - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0573 - val_accuracy: 0.9843\n",
      "Epoch 5/20\n",
      "422/422 - 30s - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0551 - val_accuracy: 0.9845\n",
      "Epoch 6/20\n",
      "422/422 - 30s - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.0517 - val_accuracy: 0.9855\n",
      "Epoch 7/20\n",
      "422/422 - 30s - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.0421 - val_accuracy: 0.9875\n",
      "Epoch 8/20\n",
      "422/422 - 31s - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0490 - val_accuracy: 0.9870\n",
      "Epoch 9/20\n",
      "422/422 - 30s - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0451 - val_accuracy: 0.9885\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9875\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-10\\assets\n",
      "--- Starting trial: run-11\n",
      "{'filter_size': 7, 'filters_number': 96}\n",
      "Epoch 1/20\n",
      "422/422 - 44s - loss: 0.2289 - accuracy: 0.9314 - val_loss: 0.0845 - val_accuracy: 0.9745\n",
      "Epoch 2/20\n",
      "422/422 - 45s - loss: 0.0629 - accuracy: 0.9802 - val_loss: 0.0585 - val_accuracy: 0.9818\n",
      "Epoch 3/20\n",
      "422/422 - 45s - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.0522 - val_accuracy: 0.9850\n",
      "Epoch 4/20\n",
      "422/422 - 46s - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.0473 - val_accuracy: 0.9867\n",
      "Epoch 5/20\n",
      "422/422 - 42s - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0456 - val_accuracy: 0.9873\n",
      "Epoch 6/20\n",
      "422/422 - 43s - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0451 - val_accuracy: 0.9878\n",
      "Epoch 7/20\n",
      "422/422 - 46s - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0421 - val_accuracy: 0.9878\n",
      "Epoch 8/20\n",
      "422/422 - 44s - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.0485 - val_accuracy: 0.9880\n",
      "Epoch 9/20\n",
      "422/422 - 47s - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0521 - val_accuracy: 0.9860\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9878\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-11\\assets\n",
      "--- Starting trial: run-12\n",
      "{'filter_size': 7, 'filters_number': 128}\n",
      "Epoch 1/20\n",
      "422/422 - 65s - loss: 0.2011 - accuracy: 0.9421 - val_loss: 0.0763 - val_accuracy: 0.9770\n",
      "Epoch 2/20\n",
      "422/422 - 65s - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.0671 - val_accuracy: 0.9820\n",
      "Epoch 3/20\n",
      "422/422 - 64s - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.0517 - val_accuracy: 0.9845\n",
      "Epoch 4/20\n",
      "422/422 - 66s - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.0533 - val_accuracy: 0.9860\n",
      "Epoch 5/20\n",
      "422/422 - 64s - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0560 - val_accuracy: 0.9843\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0517 - accuracy: 0.9845\n",
      "INFO:tensorflow:Assets written to: saved_models\\Model 2\\Run-12\\assets\n"
     ]
    }
   ],
   "source": [
    "session_num = 1\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "\n",
    "        hparams = {\n",
    "            HP_FILTER_SIZE: filter_size,\n",
    "            HP_FILTER_NUM: filter_num\n",
    "        }\n",
    "\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs\\\\Model 2\\\\hparam_tuning\\\\' + run_name, hparams, session_num)\n",
    "        \n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7764), started 0:01:00 ago. (Use '!kill 7764' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-57198155c894174a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-57198155c894174a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs/Model 2/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12812), started 0:01:13 ago. (Use '!kill 12812' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ef54be77341070af\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ef54be77341070af\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs/Model 2/fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model to evaluate on the test set\n",
    "model = tf.keras.models.load_model(r\"saved_models\\Model 2\\Run-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.argmax(model.predict(test_inputs), axis=1)\n",
    "test_accuracy = (test_targets == test_pred).sum() / test_targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 99.10%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest accuracy: {0:.2f}%'.format(test_accuracy * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
